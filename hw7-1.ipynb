{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haonan Xu Homework 7 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.33.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.23.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/belinda/opt/anaconda3/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/MLOE.txt',\n",
       " '../data/TAMatter.txt',\n",
       " '../data/OKEWFSMP.txt',\n",
       " '../data/TPP.txt',\n",
       " '../data/THWP.txt',\n",
       " '../data/TAM.txt',\n",
       " '../data/AIIMAT.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate files to a corpus\n",
    "import glob\n",
    "textfiles = glob.glob('../data/*.txt')\n",
    "textfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for file in textfiles:\n",
    "    with open(file, 'rb') as readfile:\n",
    "        text=readfile.read().lower() # keep lower case only for convenience\n",
    "        text=text.replace(b'\\n',b' ')\n",
    "        text=text.replace(b'\\r',b'')\n",
    "        text=text.replace(b\"[^a-zA-Z0-9]\",b' ')\n",
    "    corpus.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32,\n",
       " 33,\n",
       " 34,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 61,\n",
       " 63,\n",
       " 91,\n",
       " 93,\n",
       " 95,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 125,\n",
       " 132,\n",
       " 134,\n",
       " 147,\n",
       " 166,\n",
       " 167,\n",
       " 169,\n",
       " 173,\n",
       " 175,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 184,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 191,\n",
       " 194,\n",
       " 195,\n",
       " 197,\n",
       " 206,\n",
       " 207,\n",
       " 239,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 128,\n",
       " 132,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 151,\n",
       " 163,\n",
       " 166,\n",
       " 167,\n",
       " 171,\n",
       " 174,\n",
       " 176,\n",
       " 187,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 91,\n",
       " 93,\n",
       " 95,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 124,\n",
       " 128,\n",
       " 129,\n",
       " 131,\n",
       " 132,\n",
       " 134,\n",
       " 137,\n",
       " 160,\n",
       " 162,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 171,\n",
       " 173,\n",
       " 175,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 191,\n",
       " 194,\n",
       " 195,\n",
       " 197,\n",
       " 206,\n",
       " 207,\n",
       " 225,\n",
       " 226,\n",
       " 239,\n",
       " 32,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 174,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 187,\n",
       " 59,\n",
       " 182,\n",
       " 61,\n",
       " 191,\n",
       " 63,\n",
       " 195,\n",
       " 120,\n",
       " 95,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 239,\n",
       " 112,\n",
       " 111,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 113,\n",
       " 119,\n",
       " 118,\n",
       " 121,\n",
       " 122,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 36,\n",
       " 37,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 126,\n",
       " 128,\n",
       " 132,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 151,\n",
       " 163,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 169,\n",
       " 171,\n",
       " 176,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 187,\n",
       " 59,\n",
       " 191,\n",
       " 63,\n",
       " 91,\n",
       " 93,\n",
       " 95,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 239,\n",
       " 111,\n",
       " 112,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 113,\n",
       " 122,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 128,\n",
       " 130,\n",
       " 132,\n",
       " 148,\n",
       " 150,\n",
       " 153,\n",
       " 158,\n",
       " 160,\n",
       " 162,\n",
       " 163,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 171,\n",
       " 172,\n",
       " 174,\n",
       " 176,\n",
       " 177,\n",
       " 186,\n",
       " 187,\n",
       " 191,\n",
       " 194,\n",
       " 226,\n",
       " 239]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse whole corpus and find distinct chars\n",
    "distinctChar=[]\n",
    "for text in corpus:\n",
    "    distinctChar.extend(list(set(text)))\n",
    "distinctChar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{32: 0,\n",
       " 33: 1,\n",
       " 34: 2,\n",
       " 35: 3,\n",
       " 36: 4,\n",
       " 37: 5,\n",
       " 38: 6,\n",
       " 39: 7,\n",
       " 40: 8,\n",
       " 41: 9,\n",
       " 42: 10,\n",
       " 43: 11,\n",
       " 44: 12,\n",
       " 45: 13,\n",
       " 46: 14,\n",
       " 47: 15,\n",
       " 48: 16,\n",
       " 49: 17,\n",
       " 50: 18,\n",
       " 51: 19,\n",
       " 52: 20,\n",
       " 53: 21,\n",
       " 54: 22,\n",
       " 55: 23,\n",
       " 56: 24,\n",
       " 57: 25,\n",
       " 58: 26,\n",
       " 59: 27,\n",
       " 60: 28,\n",
       " 61: 29,\n",
       " 62: 30,\n",
       " 63: 31,\n",
       " 91: 32,\n",
       " 92: 33,\n",
       " 93: 34,\n",
       " 94: 35,\n",
       " 95: 36,\n",
       " 97: 37,\n",
       " 98: 38,\n",
       " 99: 39,\n",
       " 100: 40,\n",
       " 101: 41,\n",
       " 102: 42,\n",
       " 103: 43,\n",
       " 104: 44,\n",
       " 105: 45,\n",
       " 106: 46,\n",
       " 107: 47,\n",
       " 108: 48,\n",
       " 109: 49,\n",
       " 110: 50,\n",
       " 111: 51,\n",
       " 112: 52,\n",
       " 113: 53,\n",
       " 114: 54,\n",
       " 115: 55,\n",
       " 116: 56,\n",
       " 117: 57,\n",
       " 118: 58,\n",
       " 119: 59,\n",
       " 120: 60,\n",
       " 121: 61,\n",
       " 122: 62,\n",
       " 123: 63,\n",
       " 124: 64,\n",
       " 125: 65,\n",
       " 126: 66,\n",
       " 128: 67,\n",
       " 129: 68,\n",
       " 130: 69,\n",
       " 131: 70,\n",
       " 132: 71,\n",
       " 134: 72,\n",
       " 137: 73,\n",
       " 145: 74,\n",
       " 146: 75,\n",
       " 147: 76,\n",
       " 148: 77,\n",
       " 149: 78,\n",
       " 150: 79,\n",
       " 151: 80,\n",
       " 153: 81,\n",
       " 158: 82,\n",
       " 160: 83,\n",
       " 162: 84,\n",
       " 163: 85,\n",
       " 165: 86,\n",
       " 166: 87,\n",
       " 167: 88,\n",
       " 168: 89,\n",
       " 169: 90,\n",
       " 171: 91,\n",
       " 172: 92,\n",
       " 173: 93,\n",
       " 174: 94,\n",
       " 175: 95,\n",
       " 176: 96,\n",
       " 177: 97,\n",
       " 178: 98,\n",
       " 179: 99,\n",
       " 180: 100,\n",
       " 181: 101,\n",
       " 182: 102,\n",
       " 183: 103,\n",
       " 184: 104,\n",
       " 185: 105,\n",
       " 186: 106,\n",
       " 187: 107,\n",
       " 188: 108,\n",
       " 189: 109,\n",
       " 191: 110,\n",
       " 194: 111,\n",
       " 195: 112,\n",
       " 197: 113,\n",
       " 206: 114,\n",
       " 207: 115,\n",
       " 225: 116,\n",
       " 226: 117,\n",
       " 239: 118}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charMatch={}\n",
    "for i, char in enumerate(sorted(list(set(distinctChar)))): # get distinct ASCII value and map to an integer\n",
    "    charMatch[char]=i\n",
    "charMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{32: 0.0,\n",
       " 33: 0.008403361344537815,\n",
       " 34: 0.01680672268907563,\n",
       " 35: 0.025210084033613446,\n",
       " 36: 0.03361344537815126,\n",
       " 37: 0.04201680672268908,\n",
       " 38: 0.05042016806722689,\n",
       " 39: 0.058823529411764705,\n",
       " 40: 0.06722689075630252,\n",
       " 41: 0.07563025210084033,\n",
       " 42: 0.08403361344537816,\n",
       " 43: 0.09243697478991597,\n",
       " 44: 0.10084033613445378,\n",
       " 45: 0.1092436974789916,\n",
       " 46: 0.11764705882352941,\n",
       " 47: 0.12605042016806722,\n",
       " 48: 0.13445378151260504,\n",
       " 49: 0.14285714285714285,\n",
       " 50: 0.15126050420168066,\n",
       " 51: 0.15966386554621848,\n",
       " 52: 0.16806722689075632,\n",
       " 53: 0.17647058823529413,\n",
       " 54: 0.18487394957983194,\n",
       " 55: 0.19327731092436976,\n",
       " 56: 0.20168067226890757,\n",
       " 57: 0.21008403361344538,\n",
       " 58: 0.2184873949579832,\n",
       " 59: 0.226890756302521,\n",
       " 60: 0.23529411764705882,\n",
       " 61: 0.24369747899159663,\n",
       " 62: 0.25210084033613445,\n",
       " 63: 0.2605042016806723,\n",
       " 91: 0.2689075630252101,\n",
       " 92: 0.2773109243697479,\n",
       " 93: 0.2857142857142857,\n",
       " 94: 0.29411764705882354,\n",
       " 95: 0.3025210084033613,\n",
       " 97: 0.31092436974789917,\n",
       " 98: 0.31932773109243695,\n",
       " 99: 0.3277310924369748,\n",
       " 100: 0.33613445378151263,\n",
       " 101: 0.3445378151260504,\n",
       " 102: 0.35294117647058826,\n",
       " 103: 0.36134453781512604,\n",
       " 104: 0.3697478991596639,\n",
       " 105: 0.37815126050420167,\n",
       " 106: 0.3865546218487395,\n",
       " 107: 0.3949579831932773,\n",
       " 108: 0.40336134453781514,\n",
       " 109: 0.4117647058823529,\n",
       " 110: 0.42016806722689076,\n",
       " 111: 0.42857142857142855,\n",
       " 112: 0.4369747899159664,\n",
       " 113: 0.44537815126050423,\n",
       " 114: 0.453781512605042,\n",
       " 115: 0.46218487394957986,\n",
       " 116: 0.47058823529411764,\n",
       " 117: 0.4789915966386555,\n",
       " 118: 0.48739495798319327,\n",
       " 119: 0.4957983193277311,\n",
       " 120: 0.5042016806722689,\n",
       " 121: 0.5126050420168067,\n",
       " 122: 0.5210084033613446,\n",
       " 123: 0.5294117647058824,\n",
       " 124: 0.5378151260504201,\n",
       " 125: 0.5462184873949579,\n",
       " 126: 0.5546218487394958,\n",
       " 128: 0.5630252100840336,\n",
       " 129: 0.5714285714285714,\n",
       " 130: 0.5798319327731093,\n",
       " 131: 0.5882352941176471,\n",
       " 132: 0.5966386554621849,\n",
       " 134: 0.6050420168067226,\n",
       " 137: 0.6134453781512605,\n",
       " 145: 0.6218487394957983,\n",
       " 146: 0.6302521008403361,\n",
       " 147: 0.6386554621848739,\n",
       " 148: 0.6470588235294118,\n",
       " 149: 0.6554621848739496,\n",
       " 150: 0.6638655462184874,\n",
       " 151: 0.6722689075630253,\n",
       " 153: 0.680672268907563,\n",
       " 158: 0.6890756302521008,\n",
       " 160: 0.6974789915966386,\n",
       " 162: 0.7058823529411765,\n",
       " 163: 0.7142857142857143,\n",
       " 165: 0.7226890756302521,\n",
       " 166: 0.7310924369747899,\n",
       " 167: 0.7394957983193278,\n",
       " 168: 0.7478991596638656,\n",
       " 169: 0.7563025210084033,\n",
       " 171: 0.7647058823529411,\n",
       " 172: 0.773109243697479,\n",
       " 173: 0.7815126050420168,\n",
       " 174: 0.7899159663865546,\n",
       " 175: 0.7983193277310925,\n",
       " 176: 0.8067226890756303,\n",
       " 177: 0.8151260504201681,\n",
       " 178: 0.8235294117647058,\n",
       " 179: 0.8319327731092437,\n",
       " 180: 0.8403361344537815,\n",
       " 181: 0.8487394957983193,\n",
       " 182: 0.8571428571428571,\n",
       " 183: 0.865546218487395,\n",
       " 184: 0.8739495798319328,\n",
       " 185: 0.8823529411764706,\n",
       " 186: 0.8907563025210085,\n",
       " 187: 0.8991596638655462,\n",
       " 188: 0.907563025210084,\n",
       " 189: 0.9159663865546218,\n",
       " 191: 0.9243697478991597,\n",
       " 194: 0.9327731092436975,\n",
       " 195: 0.9411764705882353,\n",
       " 197: 0.9495798319327731,\n",
       " 206: 0.957983193277311,\n",
       " 207: 0.9663865546218487,\n",
       " 225: 0.9747899159663865,\n",
       " 226: 0.9831932773109243,\n",
       " 239: 0.9915966386554622}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputcharMatch={}\n",
    "for i, char in enumerate(sorted(list(set(distinctChar)))): # get distinct ASCII value and map to an integer\n",
    "    inputcharMatch[char]=i/len(sorted(list(set(distinctChar)))) # map to [0,1] for LSTM input only\n",
    "inputcharMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 32,\n",
       " 1: 33,\n",
       " 2: 34,\n",
       " 3: 35,\n",
       " 4: 36,\n",
       " 5: 37,\n",
       " 6: 38,\n",
       " 7: 39,\n",
       " 8: 40,\n",
       " 9: 41,\n",
       " 10: 42,\n",
       " 11: 43,\n",
       " 12: 44,\n",
       " 13: 45,\n",
       " 14: 46,\n",
       " 15: 47,\n",
       " 16: 48,\n",
       " 17: 49,\n",
       " 18: 50,\n",
       " 19: 51,\n",
       " 20: 52,\n",
       " 21: 53,\n",
       " 22: 54,\n",
       " 23: 55,\n",
       " 24: 56,\n",
       " 25: 57,\n",
       " 26: 58,\n",
       " 27: 59,\n",
       " 28: 60,\n",
       " 29: 61,\n",
       " 30: 62,\n",
       " 31: 63,\n",
       " 32: 91,\n",
       " 33: 92,\n",
       " 34: 93,\n",
       " 35: 94,\n",
       " 36: 95,\n",
       " 37: 97,\n",
       " 38: 98,\n",
       " 39: 99,\n",
       " 40: 100,\n",
       " 41: 101,\n",
       " 42: 102,\n",
       " 43: 103,\n",
       " 44: 104,\n",
       " 45: 105,\n",
       " 46: 106,\n",
       " 47: 107,\n",
       " 48: 108,\n",
       " 49: 109,\n",
       " 50: 110,\n",
       " 51: 111,\n",
       " 52: 112,\n",
       " 53: 113,\n",
       " 54: 114,\n",
       " 55: 115,\n",
       " 56: 116,\n",
       " 57: 117,\n",
       " 58: 118,\n",
       " 59: 119,\n",
       " 60: 120,\n",
       " 61: 121,\n",
       " 62: 122,\n",
       " 63: 123,\n",
       " 64: 124,\n",
       " 65: 125,\n",
       " 66: 126,\n",
       " 67: 128,\n",
       " 68: 129,\n",
       " 69: 130,\n",
       " 70: 131,\n",
       " 71: 132,\n",
       " 72: 134,\n",
       " 73: 137,\n",
       " 74: 145,\n",
       " 75: 146,\n",
       " 76: 147,\n",
       " 77: 148,\n",
       " 78: 149,\n",
       " 79: 150,\n",
       " 80: 151,\n",
       " 81: 153,\n",
       " 82: 158,\n",
       " 83: 160,\n",
       " 84: 162,\n",
       " 85: 163,\n",
       " 86: 165,\n",
       " 87: 166,\n",
       " 88: 167,\n",
       " 89: 168,\n",
       " 90: 169,\n",
       " 91: 171,\n",
       " 92: 172,\n",
       " 93: 173,\n",
       " 94: 174,\n",
       " 95: 175,\n",
       " 96: 176,\n",
       " 97: 177,\n",
       " 98: 178,\n",
       " 99: 179,\n",
       " 100: 180,\n",
       " 101: 181,\n",
       " 102: 182,\n",
       " 103: 183,\n",
       " 104: 184,\n",
       " 105: 185,\n",
       " 106: 186,\n",
       " 107: 187,\n",
       " 108: 188,\n",
       " 109: 189,\n",
       " 110: 191,\n",
       " 111: 194,\n",
       " 112: 195,\n",
       " 113: 197,\n",
       " 114: 206,\n",
       " 115: 207,\n",
       " 116: 225,\n",
       " 117: 226,\n",
       " 118: 239}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverseMatch = {} # for later pullbacks use\n",
    "for i, char in enumerate(sorted(list(set(distinctChar)))):\n",
    "    reverseMatch[i]=char\n",
    "\n",
    "reverseMatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iii) Choose W=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text, size):\n",
    "    wm1input=[]\n",
    "    output=[]\n",
    "    for i in range(len(text)-size+1):\n",
    "        tempinarr=[]\n",
    "        tempoutarr=[]\n",
    "        try:\n",
    "            temp_in = text[i:i+size-1] #w-1 chars\n",
    "            tempinarr.append([inputcharMatch[ord(str(t))] for t in temp_in])\n",
    "            temp_out = text[i+size-1]\n",
    "            tempoutarr.append([charMatch[ord(str(t))] for t in temp_out])\n",
    "            #print(output)\n",
    "        except:\n",
    "            #print(\"at \"+str(i)+\" iter\")\n",
    "            continue\n",
    "        for item in tempinarr:\n",
    "            wm1input.append(item)\n",
    "        for item in tempoutarr:\n",
    "            output.append(item)\n",
    "    return wm1input, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if the function works\n",
    "a,b = split_text(b'abracadabra 123 3'.decode(\"utf-8\") , 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[39], [37], [40], [37], [38], [54], [37], [0], [17], [18], [19], [0], [19]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in corpus:\n",
    "    w = 100\n",
    "    text_input = []\n",
    "    text_output = []\n",
    "    #print(text.decode(\"utf-8\") )\n",
    "    try:\n",
    "        temp_in, temp_out = split_text(text.decode(\"utf-8\") , w)\n",
    "    except:\n",
    "        continue\n",
    "    text_input.append(temp_in)\n",
    "    text_output.append(temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "numpy_input = np.asarray(text_input[0])\n",
    "numpy_output = np.asarray(text_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(715048, 99)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(715048, 99, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_input=np.reshape(numpy_input, (715048, 99, 1)) # to fit the model\n",
    "numpy_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(715048, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (v) one-hot encoding output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_output = keras.utils.to_categorical(numpy_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(715048, 108)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(256, input_shape=(99,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 256)               264192    \n",
      "=================================================================\n",
      "Total params: 264,192\n",
      "Trainable params: 264,192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (vii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(108, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 108)               27756     \n",
      "=================================================================\n",
      "Total params: 291,948\n",
      "Trainable params: 291,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5 # due to extremely slow computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (x) only able to run few epochs a time due to the long computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'checkpoints/'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='loss', save_best_only=True)\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load back and train\n",
    "load_model=keras.models.load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "699/699 [==============================] - ETA: 0s - loss: 2.5369INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "699/699 [==============================] - 1314s 2s/step - loss: 2.5369\n",
      "Epoch 2/5\n",
      "699/699 [==============================] - ETA: 0s - loss: 2.5273INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "699/699 [==============================] - 1311s 2s/step - loss: 2.5273\n",
      "Epoch 3/5\n",
      "699/699 [==============================] - ETA: 0s - loss: 2.5185INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "699/699 [==============================] - 4652s 7s/step - loss: 2.5185\n",
      "Epoch 4/5\n",
      "699/699 [==============================] - ETA: 0s - loss: 2.5089INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "699/699 [==============================] - 1351s 2s/step - loss: 2.5089\n",
      "Epoch 5/5\n",
      "699/699 [==============================] - ETA: 0s - loss: 2.4997INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "699/699 [==============================] - 1392s 2s/step - loss: 2.4997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9513ae3100>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model.fit(numpy_input, one_hot_output, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model=keras.models.load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial='There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object.'\n",
    "initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter = []\n",
    "for char in initial[-99:].lower(): # model was constructed with window size = 100\n",
    "    try: \n",
    "        starter.append(inputcharMatch[ord(str(char))])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 99, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starter = np.asarray(starter)\n",
    "starter = np.reshape(starter, (1,len(starter),1))\n",
    "starter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000): # generate a 1000 char text\n",
    "    pred = load_model.predict(starter[:100]) # predict next char\n",
    "    index = np.argmax(pred) # get best predict\n",
    "    pred_char = reverseMatch[index] # match to char\n",
    "    initial = initial+chr(pred_char) # add to original text\n",
    "    starter = np.append(starter, index)\n",
    "    starter = starter[1:]\n",
    "    starter = np.reshape(starter, (1,len(starter),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object. ihhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After 20 epochs training, the model predicts almost all 'h' (and a first 'i'). But during the first 5/10/15 epochs training, it can only predict spaces ' '. So the model is definitely improving with the checkpoints works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
